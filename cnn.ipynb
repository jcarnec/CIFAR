{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.utils import resample\n",
        "import random\n",
        "# Import necessary libraries\n",
        "from keras.datasets import cifar10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAve6DCL4JH4"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "from datetime import datetime\n",
        "\n",
        "config = {\n",
        "    'currentModel' : 'ENSEMBLE',\n",
        "    'training' : True,\n",
        "    'overFit' : False,\n",
        "    'heldOutClasses' : False,\n",
        "    'epochs' : 20,\n",
        "    'patience' : 10,\n",
        "    'startEpochs' : 1,\n",
        "    'saveModel' : True,\n",
        "    'seed': 0,\n",
        "}\n",
        "config['ensembleSize'] = 20 if 'ENSEMBLE' in config['currentModel'] else 1\n",
        "\n",
        "# Formatted as 'YYYY-MM-DD'\n",
        "today = datetime.today().strftime('%Y-%m-%d')\n",
        "\n",
        "# Get file representation of the config folder \n",
        "file_str = f'/{today}/'\n",
        "\n",
        "for key, value in config.items():\n",
        "    file_str += f'{key}-{value}_' \n",
        "\n",
        "\n",
        "MODEL_FILE = f'./models/' + file_str\n",
        "\n",
        "np.random.seed(config['seed'])\n",
        "# set random seed for tf\n",
        "tf.random.set_seed(config['seed'])\n",
        "# random seed for python built-in random module\n",
        "random.seed(config['seed'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWoEqyMuXFF4"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataset = cifar10.load_data()\n",
        "\n",
        "# Turn it into a binary classification problem by making it frogs or not frogs\n",
        "(train_images, train_labels), (test_images, test_labels) = dataset\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "# Load the dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Separate frog and not frog images\n",
        "frog_indices = np.where(train_labels == 6)[0]\n",
        "not_frog_indices = np.where(train_labels != 6)[0]\n",
        "\n",
        "if config['heldOutClasses']:\n",
        "    config['heldOutClasses'] = [0, 1]\n",
        "else:\n",
        "    config['heldOutClasses'] = []\n",
        "\n",
        "held_out_class_indices_train = np.where(np.isin(train_labels, config['heldOutClasses']))[0]    \n",
        "held_out_class_indices_test = np.where(np.isin(test_labels, config['heldOutClasses']))[0]    \n",
        "\n",
        "not_frog_indices = np.setdiff1d(not_frog_indices, held_out_class_indices_train)\n",
        "\n",
        "# Downsample majority (not frog)\n",
        "not_frog_downsampled = resample(not_frog_indices,\n",
        "                                replace=False, # sample without replacement\n",
        "                                n_samples=len(frog_indices), # match minority n\n",
        "                                random_state=27) # reproducible results\n",
        "\n",
        "# Combine minority and downsampled majority\n",
        "downsampled_indices = np.concatenate([frog_indices, not_frog_downsampled])\n",
        "\n",
        "# Downsampled feature and label sets\n",
        "train_labels = np.where(train_labels == 6, 1, 0)\n",
        "test_labels = np.where(test_labels == 6, 1, 0)\n",
        "\n",
        "train_images = train_images[downsampled_indices]\n",
        "train_labels = train_labels[downsampled_indices]\n",
        "\n",
        "test_images_held_out = test_images[held_out_class_indices_test]\n",
        "test_labels_held_out = test_labels[held_out_class_indices_test]\n",
        "\n",
        "test_images = np.delete(test_images, held_out_class_indices_test, axis=0)\n",
        "test_labels = np.delete(test_labels, held_out_class_indices_test, axis=0)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3PAELE2eSU9"
      },
      "outputs": [],
      "source": [
        "class_names = ['not_frog', 'frog']\n",
        "\n",
        "randomly_chosen_indexes = np.random.uniform(0, len(train_images), 25).astype(int)\n",
        "plt.figure(figsize=(10,10))\n",
        "for i, value in enumerate(randomly_chosen_indexes):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[value])\n",
        "    # The CIFAR labels happen to be arrays,\n",
        "    # which is why you need the extra index\n",
        "    plt.xlabel(train_labels[value])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3odqfHP4M67"
      },
      "source": [
        "### Compile and train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdDzI75PUXrG"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "\n",
        "history_list = {}\n",
        "\n",
        "history_dict_base = {\n",
        "    'accuracy': [],\n",
        "    'val_accuracy': [],\n",
        "    'loss': [],\n",
        "    'val_loss': []\n",
        "}\n",
        "\n",
        "history_dict = {}\n",
        "\n",
        "\n",
        "for i in range(config['ensembleSize']): \n",
        "    history_dict[i] = {\n",
        "    'accuracy': [],\n",
        "    'val_accuracy': [],\n",
        "    'loss': [],\n",
        "    'val_loss': []\n",
        "    }\n",
        "\n",
        "    history_list[i] = []\n",
        "\n",
        "print(history_dict)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dropout, Dense\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.layers import Input, Layer\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Function to set dropout rate\n",
        "def set_dropout_rate(model, new_rate):\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, Dropout):\n",
        "            layer.rate = new_rate\n",
        "\n",
        "\n",
        "def create_dropout_model(dropout_rate=0.5):\n",
        "    # Input layer\n",
        "    inputs = Input(shape=(32, 32, 3))\n",
        "\n",
        "    # Convolutional and MaxPooling layers\n",
        "    x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "\n",
        "    # Flatten layer\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # Dense layers with dropout\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Dense(16, activation='relu')(x)\n",
        "\n",
        "    # Output layer\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        " \n",
        "from tensorflow.keras.layers import Dropout, Dense\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def create_model():\n",
        "    # Input layer\n",
        "    inputs = Input(shape=(32, 32, 3))\n",
        "\n",
        "    # Convolutional and MaxPooling layers\n",
        "    x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "\n",
        "    # Flatten layer\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # Dense layers with dropout\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dense(16, activation='relu')(x)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9508 - auc: 0.9910 - loss: 0.1161 - val_accuracy: 0.7630 - val_auc: 0.0000e+00 - val_loss: 0.7347\n",
            "Epoch 11/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9697 - auc: 0.9947 - loss: 0.0858 - val_accuracy: 0.8115 - val_auc: 0.0000e+00 - val_loss: 0.6066\n",
            "Epoch 12/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9703 - auc: 0.9961 - loss: 0.0762 - val_accuracy: 0.8465 - val_auc: 0.0000e+00 - val_loss: 0.5130\n",
            "Epoch 1/20\n",
            "\u001b[1m 26/250\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6018 - auc: 0.5291 - loss: 0.6803"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define the early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_auc', patience=config['patience'], start_from_epoch=config['startEpochs'], restore_best_weights=True, mode='max')\n",
        "\n",
        "# Define the model checkpoint callback\n",
        "model_checkpoint = ModelCheckpoint(f'{MODEL_FILE}/{i}.keras', monitor='val_auc', save_best_only=True)\n",
        "\n",
        "callbacks = [early_stopping]\n",
        "\n",
        "if config['saveModel']:\n",
        "    callbacks.append(model_checkpoint)\n",
        "\n",
        "for i in range(config['ensembleSize']):\n",
        "\n",
        "    model = create_dropout_model() if config['currentModel'] == 'BNN' else create_model()\n",
        "    \n",
        "    model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                metrics=['accuracy', tf.keras.metrics.AUC(name='auc', curve='ROC')])\n",
        "\n",
        "    set_dropout_rate(model, np.nextafter(np.float32(0), np.float32(1))) if config['currentModel'] == 'BNN' else ''\n",
        "\n",
        "    X_train_subset, y_train_subset = resample(train_images, train_labels)\n",
        "\n",
        "    history = model.fit(X_train_subset, y_train_subset, epochs=config['epochs'],\n",
        "                        validation_data=(val_images, val_labels),\n",
        "                        callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "    set_dropout_rate(model, 0.5) if config['currentModel'] == 'BNN' else ''\n",
        "\n",
        "    history_list[i].append(history)\n",
        "\n",
        "    for history in history_list[i]:\n",
        "        for key in history_dict_base.keys():\n",
        "            history_dict[i][key].extend(history.history[key])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if config['currentModel'] == 'BNN':\n",
        "    import numpy as np\n",
        "    from tensorflow.keras.models import load_model\n",
        "\n",
        "    class MCDropoutModel:\n",
        "        def __init__(self, base_model, num_predictions=100, dropout_rate=0.5):\n",
        "            self.base_model = base_model\n",
        "            self.num_predictions = num_predictions\n",
        "            self.dropout_rate = dropout_rate\n",
        "\n",
        "        def verbose_predict(self, inputs):\n",
        "            outputs = []\n",
        "            set_dropout_rate(self.base_model, self.dropout_rate)\n",
        "            for _ in range(self.num_predictions):\n",
        "                # Enable dropout during prediction\n",
        "                outputs.append(self.base_model(inputs, training=True))\n",
        "\n",
        "            outputs_stack = tf.stack(outputs, axis=0)\n",
        "\n",
        "            return outputs_stack\n",
        "\n",
        "    loaded_model = load_model(f'{MODEL_FILE}/0.keras')\n",
        "\n",
        "    # Wrap the base model with the MCDropoutModel\n",
        "    model_under_test = MCDropoutModel(loaded_model, num_predictions=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# set_dropout_rate(loaded_model, 0.5)\n",
        "# model_with_two_predictions = MCDropoutModel(loaded_model, num_predictions=2)\n",
        "\n",
        "# predictions = model_with_two_predictions.verbose_predict(test_images[:4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if config['currentModel'] == 'ENSEMBLE':\n",
        "    from tensorflow.keras.models import Model\n",
        "    from tensorflow.keras.layers import Input, Average\n",
        "    from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "    class EnsembleModel(tf.keras.Model):\n",
        "        def __init__(self, models, **kwargs):\n",
        "            super(EnsembleModel, self).__init__(**kwargs)\n",
        "            self.models = models\n",
        "\n",
        "        def call(self, inputs):\n",
        "            # Forward pass through each model\n",
        "            outputs = [model(inputs) for model in self.models]\n",
        "\n",
        "            # Average the outputs of each model\n",
        "            # First, stack all model outputs\n",
        "            outputs_stack = tf.stack(outputs, axis=0)\n",
        "\n",
        "            # Then, calculate the mean along the first axis\n",
        "            outputs_mean = tf.reduce_mean(outputs_stack, axis=0)\n",
        "\n",
        "            return outputs_mean\n",
        "        \n",
        "        def verbose_predict(self, inputs):\n",
        "            # Forward pass through each model\n",
        "            outputs = [model(inputs) for model in self.models]\n",
        "\n",
        "            # Stack all model outputs\n",
        "            outputs_stack = tf.stack(outputs, axis=0)\n",
        "\n",
        "            return outputs_stack\n",
        "\n",
        "\n",
        "    model_list = []\n",
        "\n",
        "    for i in range(config['ensembleSize']): \n",
        "        ensemble_member = load_model(f'{MODEL_FILE}/{i}.keras')\n",
        "        ensemble_member.evaluate(test_images, test_labels)\n",
        "        model_list.append(ensemble_member)\n",
        "\n",
        "\n",
        "    # Create the ensemble model\n",
        "    model_under_test = EnsembleModel(model_list)\n",
        "\n",
        "    # Compile the ensemble model\n",
        "    model_under_test.compile(optimizer='adam',\n",
        "                        loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                        metrics=['accuracy'])\n",
        "\n",
        "    # model_under_test(test_images)\n",
        "\n",
        "    # Evaluate the ensemble model\n",
        "    performance = model_under_test.evaluate(test_images, test_labels)\n",
        "    print(performance)\n",
        "    # print('Ensemble accuracy:', accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtyDF0MKUcM7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "for i in range(config['ensembleSize']):\n",
        "    model = load_model(f'{MODEL_FILE}/{i}.keras')\n",
        "    plt.plot(history_dict[i]['accuracy'], label=f'accuracy {i}')\n",
        "    plt.plot(history_dict[i]['val_accuracy'], label = f'val_accuracy {i}')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.ylim([0.5, 1])\n",
        "\n",
        "    test_loss, test_acc, test_auc = model.evaluate(test_images,  test_labels, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def produce_df_from_predictions(model_under_test, test_images, test_labels):\n",
        "    outputs_stack = model_under_test.verbose_predict(test_images)\n",
        "    outputs_mean = np.mean(outputs_stack, axis=0)\n",
        "    outputs_variance = np.var(outputs_stack, axis=0)\n",
        "    ensemble_predictions = np.where(outputs_mean > 0.5, 1, 0)\n",
        "    individual_outputs = np.array(outputs_stack).squeeze().T.tolist()\n",
        "    output_confidence = np.abs(outputs_mean - 0.5)\n",
        "    prediction_outcome = np.where(ensemble_predictions != test_labels, 0, 1)\n",
        "    np_df = np.hstack((output_confidence, outputs_variance, prediction_outcome, outputs_mean, test_labels, ensemble_predictions))\n",
        "    df = pd.DataFrame(np_df, columns=['confidence', 'variance', 'outcome', 'mean', 'label', 'prediction'])\n",
        "    df['individual_predictions'] = individual_outputs\n",
        "    print(df.head())\n",
        "    df['tp'] = df.apply(lambda row: int(row['label'] == 1 and row['prediction'] == 1), axis=1)\n",
        "    df['fp'] = df.apply(lambda row: int(row['label'] == 0 and row['prediction'] == 1), axis=1)\n",
        "    df['tn'] = df.apply(lambda row: int(row['label'] == 0 and row['prediction'] == 1), axis=1)\n",
        "    df['fn'] = df.apply(lambda row: int(row['label'] == 1 and row['prediction'] == 0), axis=1)\n",
        "\n",
        "    df.head()\n",
        "\n",
        "    return df\n",
        "\n",
        "df = produce_df_from_predictions(model_under_test, test_images, test_labels)\n",
        "\n",
        "df_held_out = produce_df_from_predictions(model_under_test, test_images_held_out, test_labels_held_out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def normalize_and_plot(x, y, color, label=None):\n",
        "    \"\"\"Normalize and plot the given data.\"\"\"\n",
        "    # Convert to numpy for plotting\n",
        "\n",
        "    # Normalize x and y\n",
        "    # x_numpy_normalized = (x - x.min()) / (x.max() - x.min())\n",
        "    # y_numpy_normalized = (y - y.min()) / (y.max() - y.min())\n",
        "\n",
        "    # Plotting\n",
        "    plt.scatter(x, y, color=color, label=label, s=2)\n",
        "\n",
        "print()\n",
        "\n",
        "def plot_confidence_vs_variance_findings(dataframes):\n",
        "    for df in dataframes:\n",
        "        var_correct = df[df['outcome'] == 1]['variance'].to_numpy()\n",
        "        var_incorrect = df[df['outcome'] == 0]['variance'].to_numpy()\n",
        "        output_correct = df[df['outcome'] == 1]['mean'].to_numpy()\n",
        "        output_incorrect = df[df['outcome'] == 0]['mean'].to_numpy()\n",
        "        conf_correct = df[df['outcome'] == 1]['confidence'].to_numpy()\n",
        "        conf_incorrect = df[df['outcome'] == 0]['confidence'].to_numpy()\n",
        "        var_tp = df[df['tp'] == 1]['variance'].to_numpy()\n",
        "        conf_tp = df[df['tp'] == 1]['confidence'].to_numpy()\n",
        "        var_fp = df[df['fp'] == 1]['variance'].to_numpy()\n",
        "        conf_fp = df[df['fp'] == 1]['confidence'].to_numpy()\n",
        "        var_tn = df[df['tn'] == 1]['variance'].to_numpy()\n",
        "        conf_tn = df[df['tn'] == 1]['confidence'].to_numpy()\n",
        "        var_fn = df[df['fn'] == 1]['variance'].to_numpy()\n",
        "        conf_fn = df[df['fn'] == 1]['confidence'].to_numpy()\n",
        "\n",
        "        plt.figure(figsize=(6,4))\n",
        "        normalize_and_plot(var_correct, output_correct, 'blue', 'Correct Predictions')\n",
        "        normalize_and_plot(var_incorrect, output_incorrect, 'red', 'Incorrect Predictions')\n",
        "        # Add labels and legend\n",
        "        plt.title(f'Output: Correct vs Incorrect predictions')\n",
        "        plt.xlabel('Variance')\n",
        "        plt.ylabel('Output')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.figure(figsize=(6,4))\n",
        "        normalize_and_plot(var_correct, conf_correct, 'blue', 'Correct Predictions')\n",
        "        normalize_and_plot(var_incorrect, conf_incorrect, 'red', 'Incorrect Predictions')\n",
        "        # Add labels and legend\n",
        "        plt.title(f'Confidence: Correct vs Incorrect predictions')\n",
        "        plt.xlabel('Variance')\n",
        "        plt.ylabel('Confidence')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.figure(figsize=(6,4))\n",
        "        normalize_and_plot(var_tp, conf_tp, 'blue', 'TP')\n",
        "        normalize_and_plot(var_fp, conf_fp, 'red', 'FP')\n",
        "        plt.title(f'TP vs FP')\n",
        "        plt.xlabel('Variance')\n",
        "        plt.ylabel('Confidence')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.figure(figsize=(6,4))\n",
        "        normalize_and_plot(var_tn, conf_tn, 'blue', 'TN')\n",
        "        normalize_and_plot(var_fn, conf_fn, 'red', 'FN')\n",
        "        plt.title(f'TN vs FN')\n",
        "        plt.xlabel('Variance')\n",
        "        plt.ylabel('Confidence')\n",
        "        plt.legend()\n",
        "\n",
        "plot_confidence_vs_variance_findings([df])\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "tp_count = df['tp'].sum()\n",
        "tn_count = df['tn'].sum()\n",
        "fp_count = df['fp'].sum()\n",
        "fn_count = df['fn'].sum()\n",
        "\n",
        "\n",
        "accuracy = ( tp_count + tn_count ) / ( tp_count + tn_count + fp_count + fn_count )\n",
        "\n",
        "precision = tp_count / ( tp_count + fp_count )\n",
        "\n",
        "recall = tp_count / ( tp_count + fn_count )\n",
        "\n",
        "f1_score = 2 * ( ( precision * recall ) / ( precision + recall ) )\n",
        "\n",
        "confusion = confusion_matrix(test_labels, df['prediction'])\n",
        "\n",
        "# Print the results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1_score)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "true_positive_indices = df[df['tp'] == 1].sort_values('confidence', ascending=False).index.to_numpy()\n",
        "false_positive_indices = df[df['fp'] == 1].sort_values('confidence', ascending=False).index.to_numpy()\n",
        "true_negative_indices = df[df['tn'] == 1].sort_values('confidence', ascending=False).index.to_numpy()\n",
        "false_negative_indices = df[df['fn'] == 1].sort_values('confidence', ascending=False).index.to_numpy()\n",
        "\n",
        "most_confident_outputs = false_negative_indices[0:24]\n",
        "\n",
        "print(most_confident_outputs)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a 10x10 grid of subplots\n",
        "fig, axes = plt.subplots(4, 4, figsize=(20, 20))\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    # Get the index of the current image\n",
        "    index = most_confident_outputs[i]\n",
        "\n",
        "    # Display the image\n",
        "    ax.imshow(test_images[index], cmap='gray')\n",
        "\n",
        "    # Get the predictions of the individual models and the ensemble\n",
        "    # 2 x 10000 x 1\n",
        "    individual_pred = df['individual_predictions'].iloc[index]\n",
        "    ensemble_pred = df['mean'].iloc[index]\n",
        "    ensemble_var = df['variance'].iloc[index]\n",
        "\n",
        "    # Display the predictions\n",
        "    ax.set_title(f'Ensemble: {ensemble_pred}\\nVariance: {ensemble_var}\\nLabel: {test_labels[index]}')\n",
        "\n",
        "    # Remove the axis ticks\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "# Display the figure\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cnn.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
