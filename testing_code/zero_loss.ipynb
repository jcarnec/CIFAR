{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Layer, Input, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    " \n",
    "from tensorflow.keras.layers import Dropout, Dense\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model, save_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "import random\n",
    "# Import necessary libraries\n",
    "from keras.datasets import cifar10\n",
    "dataset = cifar10.load_data()\n",
    "\n",
    "config = {\n",
    "    'heldOutClasses': False,\n",
    "    'seed': 0,\n",
    "    'ensembleSize': 3,\n",
    "}\n",
    "# Turn it into a binary classification problem by making it frogs or not frogs\n",
    "(train_images, train_labels), (test_images, test_labels) = dataset\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "# Load the dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Separate frog and not frog images\n",
    "frog_indices = np.where(train_labels == 6)[0]\n",
    "not_frog_indices = np.where(train_labels != 6)[0]\n",
    "\n",
    "if config['heldOutClasses']:\n",
    "    config['heldOutClasses'] = [0, 1]\n",
    "else:\n",
    "    config['heldOutClasses'] = []\n",
    "\n",
    "held_out_class_indices_train = np.where(np.isin(train_labels, config['heldOutClasses']))[0]    \n",
    "held_out_class_indices_test = np.where(np.isin(test_labels, config['heldOutClasses']))[0]    \n",
    "\n",
    "not_frog_indices = np.setdiff1d(not_frog_indices, held_out_class_indices_train)\n",
    "\n",
    "# Downsample majority (not frog)\n",
    "not_frog_downsampled = resample(not_frog_indices,\n",
    "                                replace=False, # sample without replacement\n",
    "                                n_samples=len(frog_indices), # match minority n\n",
    "                                random_state=27) # reproducible results\n",
    "\n",
    "# Combine minority and downsampled majority\n",
    "downsampled_indices = np.concatenate([frog_indices, not_frog_downsampled])\n",
    "\n",
    "# Downsampled feature and label sets\n",
    "train_labels = np.where(train_labels == 6, 1, 0)\n",
    "test_labels = np.where(test_labels == 6, 1, 0)\n",
    "\n",
    "train_images = train_images[downsampled_indices]\n",
    "train_labels = train_labels[downsampled_indices]\n",
    "\n",
    "test_images_held_out = test_images[held_out_class_indices_test]\n",
    "test_labels_held_out = test_labels[held_out_class_indices_test]\n",
    "\n",
    "test_images = np.delete(test_images, held_out_class_indices_test, axis=0)\n",
    "test_labels = np.delete(test_labels, held_out_class_indices_test, axis=0)\n",
    "\n",
    "\n",
    "# Split the training set into training and validation sets\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=config['seed'])\n",
    "\n",
    "MODEL_FILE = './models/2024-04-30/0'\n",
    "\n",
    "def _create_model():\n",
    "    # Input layer\n",
    "    inputs = Input(shape=(32,32,3))\n",
    "\n",
    "    # Convolutional and MaxPooling layers\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "\n",
    "    # Flatten layer\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # Dense layers with dropout\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(16, activation='relu')(x)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m inputs \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Create the ensemble layer\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m ensemble_output \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_ensemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Define the rest of the model\u001b[39;00m\n\u001b[1;32m     25\u001b[0m x \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(ensemble_output)\n",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m, in \u001b[0;36mcreate_ensemble\u001b[0;34m(models, inputs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_ensemble\u001b[39m(models, inputs):\n\u001b[1;32m     12\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m [model(inputs) \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models]\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreduce_mean(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/CIFAR/.conda/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documents/CIFAR/.conda/lib/python3.11/site-packages/keras/src/backend/common/keras_tensor.py:91\u001b[0m, in \u001b[0;36mKerasTensor.__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor cannot be used as input to a TensorFlow function. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor is a symbolic placeholder for a shape and dtype, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mused when constructing Keras Functional models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor Keras Functions. You can only use it as input to a Keras layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor a Keras operation (from the namespaces `keras.layers` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand `keras.operations`). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are likely doing something like:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = Input(...)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_fn(x)  # Invalid.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat you should do instead is wrap `tf_fn` in a layer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass MyLayer(Layer):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def call(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return tf_fn(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = MyLayer()(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "class DNNEnsemble(tf.keras.layers.Layer):\n",
    "    def __init__(self, models=[], **kwargs):\n",
    "        super(DNNEnsemble, self).__init__(**kwargs)\n",
    "        self.models = models\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = [model(inputs) for model in self.models]\n",
    "        return tf.reduce_mean(tf.stack(outputs, axis=0), axis=0)\n",
    "\n",
    "\n",
    "# Create an ensemble of models\n",
    "model_list = [load_model(f\"model_{i}.h5\") for i in range(config['ensembleSize'])]\n",
    "\n",
    "# Create the DNNEnsemble layer with input shape specified\n",
    "ensemble = DNNEnsemble(models=model_list)\n",
    "\n",
    "# Define the rest of the model\n",
    "inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "x = ensemble(inputs)  # Using the ensemble as a layer\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the functional model\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(train_images, train_labels)\n",
    "print(f\"Model accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# class OutputAggregationLayer(Layer):\n",
    "#     def __init__(self):\n",
    "#         super(OutputAggregationLayer, self).__init__()\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         # Assume inputs is a list of tensors from the ensemble models\n",
    "#         return tf.reduce_mean(tf.stack(inputs, axis=0), axis=0)\n",
    "\n",
    "# class DNNEnsemble(Model):\n",
    "#     def __init__(self, models=[], input_shape=(32, 32, 3)):\n",
    "#         super(DNNEnsemble, self).__init__()\n",
    "#         self.models = models\n",
    "#         self.agg_layer = OutputAggregationLayer()\n",
    "#         self.build(input_shape)\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         self.inputs = Input(shape=input_shape)\n",
    "#         # Collect outputs from each model in a list\n",
    "#         outputs = [model(self.inputs) for model in self.models]\n",
    "#         self.outputs = self.agg_layer(outputs)\n",
    "#         self.model = Model(inputs=self.inputs, outputs=self.outputs)\n",
    "    \n",
    "#     def call(self, inputs):\n",
    "#         outputs = [model(inputs, trainable=False) for model in self.models]\n",
    "#         return self.agg_layer(outputs)\n",
    "    \n",
    "#     def compile(self, optimizer='adam', loss='binary_crossentropy', metrics=[]):\n",
    "#         super(DNNEnsemble, self).compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "#         self.model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "#     def fit(self, *args, **kwargs):\n",
    "#         return self.model.fit(*args, **kwargs)\n",
    "\n",
    "#     def evaluate(self, *args, **kwargs):\n",
    "#         return self.model.evaluate(*args, **kwargs)\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     model_list = []\n",
    "\n",
    "#     def train_and_save_model(i):\n",
    "#         model = _create_model()  # Ensure _create_model compiles the model\n",
    "#         # Fit the model\n",
    "#         model.fit(train_images, train_labels, epochs=5, batch_size=32)\n",
    "#         # Save the model\n",
    "#         save_model(model, f\"model_{i}.h5\")\n",
    "\n",
    "#     # Example usage:\n",
    "#     # for i in range(config['ensembleSize']):\n",
    "#     #     train_and_save_model(i)\n",
    "\n",
    "#     # Create an ensemble of 3 models\n",
    "#     model_list = [load_model(f\"model_{i}.h5\") for i in range(config['ensembleSize'])]\n",
    "\n",
    "#     ensemble = DNNEnsemble(models=model_list, input_shape=(32, 32, 3))\n",
    "#     # Compile the ensemble\n",
    "#     ensemble.compile(metrics=['accuracy'])\n",
    "\n",
    "#     ensemble.fit(train_images, train_labels, epochs=5, batch_size=32)\n",
    "\n",
    "#     # Evaluate the ensemble\n",
    "#     loss, accuracy = ensemble.evaluate(train_images, train_labels)\n",
    "#     print(f\"Ensemble accuracy: {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
